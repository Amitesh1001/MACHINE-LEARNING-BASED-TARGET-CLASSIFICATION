# MACHINE-LEARNING-BASED-TARGET-CLASSIFICATION
Classification of ground vehicles by extracting the features from their acoustic signal and finding best algorithm for the model based on accuracy using half of the signal.
##Abstract
Classification is the ability of a system to identify a sound into its specific category with an acceptable classification accuracy score. This project is able to convert the given audio to spectrograms and use these images as data to train the model to perform classification on a new audio signal. Deep learning with deep neural networks is implemented in this project which makes the system more accurate and reliable.
The main objective of this project is to devise a Deep Neural Network (DNN) for      a vehicle classification system that can categorize a given audio sample into three dif- ferent categories. A Convolutional Neural Network (CNN) and Recurrent Neural Net- work(RNN) are the type of Deep Neural Networks employed in this project, which is trained using the generated mel-spectrogram images.  With the help of Google Collab  the network is designed and imported into python. The system is designed to perform various tasks as this language provides many predefined functions such as Librosa and Sklearn giving a strong platform for implementation and provides a continuous interface between the user and the computer system.
The neural network is devised by choosing the best possible learning rate and number of iterations to train using the dataset. Softmax function is used to decide the most appropriate learning rate which is obtained by comparing the graph of the basic soft-  max function with the obtained graph. As a result, Convolutional Neural Networks and Recurrent Neural Networks are trained with an accuracy ranging between 85-95 in the process to demonstrate a comparative analysis. A vehicle classification using a deep neu- ral network is designed to perform different tasks which have environmental and security applications.
##Objectives
*To classify audio signals into Footsteps, Type-A (Amphibious Assault Vehicle) and Type-B(Dragon Wagon).
*To extract MEL spectrogram and MEL Frequency Cepstral Coefficients as features for CNN and RNN respectively.
*CNN and RNN models are trained and	 tested with full signal and half signal duration signals - to check which model is best for specific durations and denominations.
*Test and compare Convolution Neural Networks and Recurrent Neural Networks(CNN and RNN) - to evaluate which performs the best on the dataset.
